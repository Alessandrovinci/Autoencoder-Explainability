# Anomaly Detection and clarification using Autoencoder and Shap Values
An autoencoder can be used to detect anomalies through the reconstruction error (anomaly score). An autoencoder represents the data in lower dimensionality (encoding) and reconstructs the data into the original dimensionality (decoding). Based on the input, the autoencoder learns an identity function so that the autoencoder's output is similar to the input and the embedded model created in encoding represents normal instances well. In contrast, anomalies are not reconstructed well and have a high amount of reconstruction error, so in the process of encoding and decoding the instances, the anomalies are discovered. A set of top-k most intense outliers are returned to the user for further inspection; however, the manual validation of results becomes challenging without justification or additional clues. An explanation of why an instance is anomalous enables the experts to focus their investigation on the most important anomalies and may increase their trust in our approach.

The challenge was then to design a method for explaining an anomaly revealed by an autoencoder (unsupervised). Unlike existing explainability methods which are used to explain a predicted array during a supervised task, the autoencoder output is a completely new database of reconstructed values and for this reason, a standard approach to feature explainability does not lead to any solution.

That's why I implemented a 5 step process to apply Shap values to an autoencoder output to explain which features were the most important for the recognized anomaly, and which on the other hand, were the features that were producing noise and offsetting the anomaly.
For each single observation:
1. determine the reconstruction error predicted by the autoencoder
2. Select the top 5 features that contributed to the reconstruction error score
3. Use the sign of the reconstruction error to determine if the feature is offsetting or contributing to the anomaly score
4. For each feature of this top 5, compute an array of Shap values to understand the impact of all the other features on this one.
     You will now have 5 arrays, 1 for each top feature of lenght n (where n is the total number of features)
5. Aggregate the five feature scores arrays in 1 to get a final shap array for the initial single observation

repeat for all the observations to create a Shap database where you can understand the impact of each single feature on the anomaly score generated by the autoencoder for each specific observation.

Thanks!
   


