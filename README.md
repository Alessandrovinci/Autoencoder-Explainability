# Anomaly Detection and clarification using Autoencoder and Shap Values
An autoencoder can be used to detect anomalies through the reconstruction error (anomaly score). The way it works, is that given and initial set of observations, the model converts them into new set of data with a lower dimension (encoding) and then it tries to reconstructs the original observations changing them back to the initial dimensionality (decoding). This is done by analyzing the starting input, and learning an identity function that is applied to the middle layer to generate an output that is optimized at each training iteration. 
In the end, when the autoencoder is analyzing a normal instance of your observation, the reconstrcuted output will be easily predicted and it will be very similar to the original input. In contrast, anomalies will be difficult to reconstruct correctly and will display a high reconstruction error. 
When we want to identify the top k anomalies in a dataset, we just need to return the K outliers that achieved the highest reconstruction error and let the user continue with a further inspection; however, the manual validation of results becomes challenging without justification or additional clues. An explanation of why an instance is anomalous enables the experts to focus their investigation on the most important anomalies and may increase their trust in our approach.

The challenge was then to design a method for explaining an anomaly revealed by an autoencoder (unsupervised). Unlike existing explainability methods which are used to explain a predicted array during a supervised task, the autoencoder output is a completely new database of reconstructed values and for this reason, a standard approach to feature explainability does not lead to any solution.

That's why I implemented a 5 step process to apply Shap values to an autoencoder output to explain which features were the most important for the recognized anomaly, and which on the other hand, were the features that were producing noise and offsetting the anomaly.
For each single observation:
1. determine the reconstruction error predicted by the autoencoder
2. Select the top 5 features that contributed to the reconstruction error score
3. Use the sign of the reconstruction error to determine if the feature is offsetting or contributing to the anomaly score
4. For each feature of this top 5, compute an array of Shap values to understand the impact of all the other features on this one.
     You will now have 5 arrays, 1 for each top feature of lenght n (where n is the total number of features)
5. Aggregate the five feature scores arrays in 1 to get a final shap array for the initial single observation

repeat for all the observations to create a Shap database where you can understand the impact of each single feature on the anomaly score generated by the autoencoder for each specific observation.

Thanks!
   


